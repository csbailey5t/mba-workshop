---
title: "MBA Data Exploration"
author: "Scott Bailey"
date: "4/16/2020"
output: html_document
---

```{r}
install.packages(c("tidyverse", 
                 "forcats",
                 "skimr",
                 "tidylog",
                 "mgcv",
                 "lubridate",
                 "gratia"))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse, warn.conflicts = FALSE)
library(tidylog, warn.conflicts = FALSE)
library(skimr)
library(mgcv)
library(lubridate)
library(gratia)
library(forcats)
```

```{r data-imports}
features <- read_csv("data/features.csv")
stores <- read_csv("data/stores.csv")
test_df <-read_csv("data/test.csv")
train_df <- read_csv("data/train.csv")
sample_submission_df <- read_csv("data/sampleSubmission.csv")
```
```{r}
skim(train_df)
```
```{r}
train_df %>%
  filter(Store == 1) %>%
  filter(Dept == 1) %>%
  ggplot(aes(Date, Weekly_Sales, color = IsHoliday)) +
  geom_point()
```

Let's try to model a single department of a single store using a generalized additive model. We'll need to break apart the Date column into numeric variables
 
```{r}
train_dat_1_1 <- train_df %>%
  filter(Store == 1) %>%
  filter(Dept == 1) %>%
  mutate(
    Day = day(Date),
    Month = month(Date),
    Year = year(Date),
    Week = week(Date)
  )

head(train_dat_1_1)
```
 
```{r}
ggplot(train_dat_1_1, aes(x=IsHoliday, y=Weekly_Sales)) +
  geom_point()
```
 
 
```{r}
gam_mod <- gam(Weekly_Sales ~ s(Week), data = train_dat_1_1, method="REML")

draw(gam_mod) 
plot(gam_mod, residuals = TRUE, pch = 1, cex = 1, shade = TRUE)
```
```{r}
ggplot(data = train_dat_1_1, aes(x = Week, y = Weekly_Sales, color = Year)) +
  geom_point(aes(shape = IsHoliday)) +
  geom_line(aes(x=Week, y=fitted(gam_mod)))
```
 
 Let's take a look at the full training data. 
 
```{r}
train_mod <- train_df %>%
  mutate(
    Day = day(Date),
    Month = month(Date),
    Year = year(Date),
    Week = week(Date),
    Store = as_factor(Store),
    Dept = as_factor(Dept)
  )
  

head(train_mod)
```
 
Let's do some exploratory graphing with some groupby statements. 

```{r}
train_mod %>%
  group_by(Store) %>%
  summarise(total_sales = sum(Weekly_Sales)) %>%
  ggplot(aes(x = Store, y = total_sales)) +
  geom_col()
  
  
```
```{r}
train_mod %>%
  group_by(Dept) %>%
  summarise(total_sales = sum(Weekly_Sales)) %>%
  ggplot(aes(x = Dept, y = total_sales)) +
  geom_col()
```

```{r}
train_mod %>%
  ggplot(aes(x = Week, y = Weekly_Sales, color = Year)) +
  geom_point(aes(shape = IsHoliday))
```


Train a GAM on whole data - THESE ARE SLOW AND NOT EFFECTIVE BC THE DATA DOESNT HAVE AN UNDERLYING RELATIONSHIP. THEY HAVE TO BE GROUPED BY STORE
```{r}
gam_mod_w <- gam(Weekly_Sales ~ s(Week) + Store + Dept, data = train_mod, method="REML")

gam_mod_w <- gam(Weekly_Sales ~ s(Week, by=Store) + Store, data = train_mod, method="REML")
```
```{r}
train_1 <- train_mod %>%
  filter(Store == 1)

train_1 %>%
  ggplot(aes(x = Week, y = Weekly_Sales)) +
  geom_point() +
  facet_wrap(vars(Dept))
```

 
Need to group by store to get aggregate sum of weekly sales
Facet on store, department, year
 
 
## Switch to working on features.csv file
 
```{r}
skim(features)
```
 
Will want to merge with training file or store file at some point.


Count the number of obs for each store
```{r}
features %>%
  group_by(Store) %>%
  count() 
```

Let's figure out the average fuel price for each store

```{r}
features %>%
  group_by(Store) %>%
  summarize(avg_fuel = mean(Fuel_Price)) %>%
  ggplot(aes(Store, avg_fuel)) +
  geom_col()
```

Let's do the same for temperature

```{r}
features %>%
  group_by(Store) %>%
  summarize(avg_temp = mean(Temperature)) %>%
  ggplot(aes(Store, avg_temp)) +
  geom_col()
```

Let's look at just the temp for a single store over time. 

```{r}
features %>%
  filter(Store == 1) %>%
  ggplot(aes(Date, Temperature)) +
  geom_point()
```

Let's do the same to gas prices

```{r}
features %>%
  filter(Store == 1) %>%
  ggplot(aes(Date, Fuel_Price)) +
  geom_point()
```

What if we just do a scatter plot with all temperatures

```{r}
features %>%
  ggplot(aes(Date, Temperature)) +
  geom_point()
```

We could do the same thing, but color the points by store.

```{r}
features %>%
  ggplot(aes(Date, Temperature)) +
  geom_point(aes(color=Store))
```

```{r}
features %>%
  mutate(Store = as_factor(Store)) %>%
  ggplot(aes(Date, Temperature)) +
  geom_point(aes(color=Store), alpha=0.2) +
  scale_color_discrete()
```

That's a lot to look at, so let's take a sample of stores, then plot a scatterplot where the x and y correspond to temperature and fuel cost. 

```{r}
sample_stores = sample(1:50, 10)
features %>%
  filter(Store %in% sample_stores) %>%
  mutate(Store = as_factor(Store)) %>%
  ggplot(aes(Temperature, Fuel_Price)) +
  geom_point(aes(color=Store), alpha=0.2) +
  scale_color_discrete()
  
```

An example of facets in ggplot

```{r}
features %>%
  filter(Store %in% sample_stores) %>%
  mutate(Store = as_factor(Store)) %>%
  ggplot(aes(Temperature, Fuel_Price)) +
  geom_point(aes(color=Store), alpha=0.2) +
  scale_color_discrete() +
  facet_wrap(~ Store)
```

The consistency of this shape is really interesting. Let's see if we can break it down just a bit more to figure out whether another variable, like the year might be impacting it. 

```{r}
features %>%
  filter(Store %in% sample_stores) %>%
  mutate(Year = as_factor(year(Date))) %>%
  mutate(Store = as_factor(Store)) %>%
  ggplot(aes(Temperature, Fuel_Price)) +
  geom_point(aes(color=Store, shape=Year), alpha=0.2) +
  scale_color_discrete() +
  facet_wrap(~ Store)
```

Do something with CPI.

```{r}
skim(features$CPI)
```


```{r}
features %>%
  ggplot(aes(Temperature, CPI)) +
  geom_point()
```

```{r}
features %>%
  ggplot(aes(Date, CPI)) +
  geom_point()
```


```{r}
features %>%
  ggplot(aes(CPI, Unemployment)) +
  geom_point()
```

Do avg CPI with different groupings
Histogram of CPI?
Do a viz with a mean line somewhere. 
Handle missing data explicitly
Join datasets?
Something with groupby of multiple columns 
Use glimpse and summary 
Build in some activities
